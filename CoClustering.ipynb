{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender for Amazon Books with Co Clustering and more\n",
    "<p>Based on https://www.analyticsvidhya.com/blog/2016/06/quick-guide-build-recommendation-engine-python/</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We first download and initilise surprise from http://surpriselib.com/</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in /home/bs/anaconda3/lib/python3.6/site-packages\r\n",
      "Requirement already satisfied: numpy>=1.11.2 in /home/bs/anaconda3/lib/python3.6/site-packages (from scikit-surprise)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /home/bs/anaconda3/lib/python3.6/site-packages (from scikit-surprise)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Then we import all the libraries we use</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from surprise import Reader\n",
    "from surprise import CoClustering\n",
    "from surprise import Dataset\n",
    "from surprise import evaluate, print_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Lastly, we read our data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# path to dataset file\n",
    "file_path = 'data.csv'\n",
    "\n",
    "# As we're loading a custom dataset, we need to define a reader. In \n",
    "# our data, each line has the following format:\n",
    "# 'user item rating timestamp', separated by '\\t' characters.\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',')\n",
    "\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "data.split(n_folds=5) #Todo, consider # of folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-Clustering\n",
    "<p>This is based on >>>>>>>>>>>>>>> http://surprise.readthedocs.io/en/stable/co_clustering.html?highlight=co%20clustering </p>\n",
    "Talk about this algo, as well as surprise project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm CoClustering.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 1.1882\n",
      "MAE:  0.8555\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 1.1766\n",
      "MAE:  0.8458\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 1.1718\n",
      "MAE:  0.8420\n",
      "------------\n",
      "Fold 4\n",
      "RMSE: 1.1670\n",
      "MAE:  0.8381\n",
      "------------\n",
      "Fold 5\n",
      "RMSE: 1.1712\n",
      "MAE:  0.8425\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 1.1750\n",
      "Mean MAE : 0.8448\n",
      "------------\n",
      "------------\n",
      "        Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    \n",
      "RMSE    1.1882  1.1766  1.1718  1.1670  1.1712  1.1750  \n",
      "MAE     0.8555  0.8458  0.8420  0.8381  0.8425  0.8448  \n"
     ]
    }
   ],
   "source": [
    "# We'll use the Co Clustering algorithm.\n",
    "algo = CoClustering()\n",
    "\n",
    "# Evaluate performances of our algorithm on the dataset.\n",
    "perf = evaluate(algo, data, measures=['RMSE', 'MAE']) #Root Mean Squared Error & Mean Absolute Error.\n",
    "\n",
    "print_perf(perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Then we perform a few predictions</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = 4.00   est = 4.32   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "uid = str(196)  # raw user id (as in the ratings file). They are **strings**!\n",
    "iid = str(302)  # raw item id (as in the ratings file). They are **strings**!\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(uid, iid, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Just for fun, we also perform Co Clustering on a single full set</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = 4.00   est = 4.32   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the trainset.\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Build an algorithm, and train it.\n",
    "algo = CoClustering()\n",
    "algo.train(trainset)\n",
    "\n",
    "#Prediction\n",
    "uid = str(196)  # raw user id (as in the ratings file). They are **strings**!\n",
    "iid = str(302)  # raw item id (as in the ratings file). They are **strings**!\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(uid, iid, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>No difference, which seems quite odd</p>\n",
    "\n",
    "<p>Let's try to run a Matrix Factorization-based algorithm</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 1.0478\n",
      "MAE:  0.7361\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 1.0456\n",
      "MAE:  0.7369\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 1.0432\n",
      "MAE:  0.7348\n",
      "------------\n",
      "Fold 4\n",
      "RMSE: 1.0452\n",
      "MAE:  0.7347\n",
      "------------\n",
      "Fold 5\n",
      "RMSE: 1.0436\n",
      "MAE:  0.7363\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 1.0451\n",
      "Mean MAE : 0.7358\n",
      "------------\n",
      "------------\n",
      "        Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    \n",
      "RMSE    1.0478  1.0456  1.0432  1.0452  1.0436  1.0451  \n",
      "MAE     0.7361  0.7369  0.7348  0.7347  0.7363  0.7358  \n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "# We'll use the Matrix Factorization-based algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Evaluate performances of our algorithm on the dataset.\n",
    "perf = evaluate(algo, data, measures=['RMSE', 'MAE']) #Root Mean Squared Error & Mean Absolute Error.\n",
    "\n",
    "print_perf(perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = 4.00   est = 4.32   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "uid = str(196)  # raw user id (as in the ratings file). They are **strings**!\n",
    "iid = str(302)  # raw item id (as in the ratings file). They are **strings**!\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(uid, iid, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Odd. We look into this issue in future. We get a better RMSE, yet the same reccomendation is performed. We will have to look into how the difference is defined in Surprise, as well as print out some more reccomendations.</p> - yes, I'm a we atm. :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
